# Teste T√©cnico - Est√°gio em Desenvolvimento (Intuitive Care)

Este projeto √© uma solu√ß√£o completa de **ETL (Extra√ß√£o, Transforma√ß√£o e Carga)** e **API** para consulta de dados de operadoras de planos de sa√∫de, utilizando dados p√∫blicos da ANS.

---

## üõ† Tecnologias Utilizadas

* **Linguagem:** `Python 3.9`
* **Automa√ß√£o/Scraping:** `Selenium`, `os`, `zipfile`
* **Banco de Dados:** `PostgreSQL`
* **API:** `Flask` 
* **ORM:** `SQLAlchemy`
* **Frontend:** `Vue.js (Vite)`

---
## üíª Como Executar o Projeto (Via Docker)

A aplica√ß√£o foi totalmente "dockerizada" para garantir que rode em qualquer m√°quina sem necessidade de configurar ambiente Python, Node.js ou Banco de Dados manualmente.

### üìã Pr√©-requisitos
* **Docker** e **Docker Compose** instalados e rodando.

### Passo a Passo
1. Abra o terminal na raiz do projeto.

   ```
    cd projeto-intuitive
2. Execute o comando de constru√ß√£o e inicializa√ß√£o:

   ```
   docker-compose up --build
3. Aguarde a inicializa√ß√£o:
O **Docker** ir√° baixar as depend√™ncias e subir 3 servi√ßos: **Frontend**, **Backend** e **Data Base**.

* Um servi√ßo autom√°tico de ETL (intuitive_etl) iniciar√° o download dos dados da ANS. Isso pode levar alguns minutos. Acompanhe os logs no terminal.
  
## üîó Acessando a Aplica√ß√£o
Ap√≥s os containers subirem, acesse o Frontend :
```
http://localhost:5173
```
API Backend :
```
http://localhost:5000/api/operadoras
```
Banco de Dados PostgresSQL (User: postgres / Pass: password) :
```
localhost:5432
```
## üí° Decis√µes T√©cnicas e Trade-offs

Como este √© um teste para est√°gio e com prazo curto, priorizei ferramentas que eu j√° dominava para a parte l√≥gica e "quebrei a cabe√ßa" para aprender as tecnologias novas (Postgres,Postman e criar APIs ) durante a semana. Abaixo explico os porqu√™s:

### Python vs Java
Optei pelo **Python** pois √© a linguagem onde tenho mais experi√™ncia pr√°tica. Como o prazo era curto, usar uma linguagem familiar me permitiu focar nos desafios novos (como a modelagem do banco e a API) sem me preocupar com a sintaxe. 
* **Ferramentas e modelagem de dados** O Python √© uma linguagem extremamente consolidada no tratamento de dados. Utilizei a biblioteca Pandas pela sua alta performance no processamento de grandes volumes de informa√ß√µes, o SQLAlchemy para garantir uma camada de seguran√ßa e abstra√ß√£o no banco de dados, e o Flask pela agilidade na constru√ß√£o da API. Acredito que esta foi a escolha correta para o projeto, pois uniu minha experi√™ncia pr√©via com ferramentas que se complementam perfeitamente para entregar uma solu√ß√£o robusta.

### Banco de Dados (PostgreSQL)
A instru√ß√£o do teste permitia MySQL ou PostgreSQL. Mesmo nunca tendo desenvolvido com **PostgreSQL**, escolhi ele n√£o somente por ser o padr√£o da ind√∫stria para dados, mas porque ele tamb√©m utiliza do princ√≠pio ACID (Atomicidade, Consist√™ncia, Isolamento e Durabilidade) trazendo seguran√ßa para os dados monet√°rios. 

**Objet Relational Mapping:** Usei a lib **SQLAlchemy** para facilitar o desenvolvimento com a utiliza√ß√£o de ORMs que utilizam de classes e objetos, sendo mais similar com minhas experi√™ncias anteriores de desenvolvimento ao inv√©s do SQL puro, que √© novo para mim. 

**Normaliza√ß√£o:** Criei duas tables `operadoras_ativas` e `despesas_consolidadas` . Isso evita repetir dados como Raz√£o social e CNPJ diversas vezes na tabela de despesas, economizando armazenamento e facilitando atualiza√ß√£o dos dados da operadora.

**Tipos de Dados:** Para a coluna `vl_saldo_final`, utilizei `Numeric(18,2)` garantindo exatid√£o com centavos e limitando a apenas duas casas ap√≥s a virgula, j√° que float √© impreciso e isso pode causar prejuizos monet√°rios, principalmente com grandes volumes de dados.

* **Seguran√ßa:** SQLalchemy tamb√©m traz uma camada de seguran√ßa contra SQL injection, j√° que ele n√£o utiliza diretamente concatena√ß√£o, trazendo esse adicional de seguran√ßa muito interessante ao projeto e que tamb√©m foi solicitado no teste.

### Estrat√©gia de ETL (Selenium e Limpeza)

* **Extra√ß√£o:** Usei **Selenium** em modo *headless* para baixar os arquivos ZIP. A automa√ß√£o com selenium foi a parte onde me senti mais confort√°vel, pois j√° tenho experi√™ncia profissional com automa√ß√£o de arquivos e pastas (`os`, `zipfile`).
  
* **Processamento na mem√≥ria:** Optei por processar os arquivos na mem√≥ria via Pandas, devido ao tamanho dos arquivos. Em m√©dia eles eram arquivos de 60mb, ent√£o n√£o iriam consumir muita ram e consguiriam facilmente ser rodados por m√°quinas com 16gb de ram. O processamento em mem√≥ria tamb√©m √© MUITO mais r√°pido que o incremental, o que torna ainda mais interessante processa-los em mem√≥ria nesse caso.

* **Valida√ß√£o de CNPJ:** Utilizei a biblioteca validate-docbr para garantir a integridade dos dados. Por ser uma solu√ß√£o consolidada para documentos brasileiros,isso segue o princ√≠pio KISS (Keep It Simple) solicitado no teste, evitando "reinventar a roda". A biblioteca valida o CNPJ matematicamente e, caso o n√∫mero seja inv√°lido, optei por descartar o registro. Essa decis√£o prioriza a confiabilidade da base de dados em detrimento da quantidade, garantindo que apenas informa√ß√µes consistentes sejam processadas.

* **Estrat√©gia de Join (Inner Join)** : Fiz um Inner Join entre as Despesas e o Cadastro de Operadoras, j√° que s√≥ me interessam despesas de operadoras que tenham cadastro ativo e v√°lido na ANS. Registros "√≥rf√£os" (despesas sem operadora cadastrada) foram ignorados para manter a consist√™ncia relacional.
  
* **Filtragem de Despesas:** Para identificar o que era despesa administrativa, filtrei pelo c√≥digo cont√°bil iniciando em **"411"**. Achei mais seguro converter tudo para *string* antes de processar para n√£o perder zeros √† esquerda ou sofrer com arredondamentos.
  
* **Duplicatas:** Percebi que os arquivos da ANS traziam valores incrementais e repetidos, ao ordenar os valores em ordem descrescente (como pede o teste). Minha solu√ß√£o foi ordenar os valores de forma decrescente e ent√£o manter apenas o **maior valor** (o mais atual) para cada CNPJ/Trimestre, garantindo que o banco n√£o ficasse sujo.

### Constru√ß√£o da API (Flask)
Como eu nunca havia desenvolvido uma API antes (apenas consumido), escolhi o **Flask**.

* **Por que n√£o Django/FastAPI?** O Flask √© mais minimalista. Para o escopo do teste, achei melhor fazer algo simples que eu conseguisse entender e explicar, do que usar um framework complexo e me perder na configura√ß√£o.
  
* **Pagina√ß√£o:** Implementei uma pagina√ß√£o simples baseada em `page` e `limit` (**Offset**) para pular registros em valores pr√©-determinados. Eu j√° havia usado offset em outro projeto e tamb√©m funcionou bem para o volume de dados dessa vez, evitando que houvesse muito tempo para carregar os elementos no DOM ou at√© travar o navegador.

* **Busca e Filtro (Server-side):** A busca pela raz√£o social ou CNPJ √© feita via query SQL (`ILIKE`) buscando o termo fornecido pelo usu√°rio na query **SQL**. Assim o banco filtra a base de dados primeiro e ent√£o devolve o output com at√© 10 resultados para o frontend.

*  **Cache:** Optei por n√£o usar cache (Redis) na rota de estat√≠sticas. Os dados s√≥ mudam trimestralmente (quando o ETL roda). O PostgreSQL lida bem com as agrega√ß√µes atuais. Adicionar Redis traria complexidade de infraestrutura desnecess√°ria para o escopo deste MVP.

### Frontend Vue.js (Vite):

* **Gerenciamento de Estado:** Utilizei `Props` e estado local. Para uma aplica√ß√£o deste tamanho, usar bibliotecas complexas como Vuex ou Pinia seria excesso de engenharia ("Overengineering"). Manter o estado simples facilitou o desenvolvimento e a leitura do c√≥digo.
